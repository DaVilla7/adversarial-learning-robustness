{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to fool a pre-trained ResNet50 model by launching a simple PGD-based attack (Projected Gradient Descent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tf.keras.applications.resnet50 import decode_predictions\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first download a sample image which we will perturb in order to fool our pre-trained image classifier. We also download a dictionary that contains the mapping between the Imagenet dataset class labels and their ids (the ResNet50 model is pre-trained on ImageNet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://adversarial-ml-tutorial.org/introduction/pig.jpg\n",
    "!wget -q https://raw.githubusercontent.com/USCDataScience/dl4j-kerasimport-examples/master/dl4j-import-example/data/imagenet_class_index.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few early constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 2./255\n",
    "IMAGENET_LABELS = \"imagenet_class_index.json\"\n",
    "\n",
    "with open(IMAGENET_LABELS) as f:\n",
    "    IMAGENET_CLASSES = {int(i):x[1] for i,x in json.load(f).items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a couple of utility functions that we will be using throughout the course of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load up an image from a local filepath and\n",
    "# display it\n",
    "def show_image(image_path):\n",
    "    image_pixels = plt.imread(image_path)\n",
    "    plt.imshow(image_pixels)\n",
    "    plt.show()\n",
    "    return image_pixels\n",
    "\n",
    "# Function to preprocess an image for performing inference\n",
    "def preprocess_image(image_pixels, preprocess=False):\n",
    "    if preprocess:\n",
    "        image_pixels = preprocess_input(image_pixels)\n",
    "    image_pixels = cv2.resize(image_pixels, (224, 224))\n",
    "    image_pixels = np.expand_dims(image_pixels, axis=0)\n",
    "\n",
    "    return image_pixels\n",
    "\n",
    "# Clipping utility to project delta back to our favorable pixel\n",
    "# range ([0 ,1])\n",
    "def clip_eps(delta_tensor):\n",
    "    return tf.clip_by_value(delta_tensor, \n",
    "                            clip_value_min=-EPS, \n",
    "                            clip_value_max=EPS)\n",
    "\n",
    "# Parse the label\n",
    "def get_label(preds):\n",
    "    print(IMAGENET_CLASSES[preds.argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our first image and pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = show_image(\"pig.jpg\")\n",
    "preprocessed_image = preprocess_image(sample_image, preprocess=True)\n",
    "resnet50 = tf.keras.applications.ResNet50(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference with a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = resnet50.predict(preprocessed_image)\n",
    "print(\"Predicted:\", decode_predictions(preds, top=3)[0])\n",
    "print(\"Class idx:\", preds.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just as a sanity check, a model having a very confidence about its prediction in this case should have a very low cross-entropy loss. Let's verify that. Also, if trace back the loss we should get the exact top-1 confidence we got above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "loss = cce(\n",
    "    tf.convert_to_tensor([preds.argmax()]),\n",
    "    tf.convert_to_tensor(preds)\n",
    ")\n",
    "print(\"Cross-entropy loss\", loss.numpy())\n",
    "print(\"Top-1 confidence\", np.exp(-loss.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write our utility functions for launching a simple PGD-based attack. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for adversarial attacks\n",
    "\n",
    "In this attack we will use PGD to simply increase the loss for the given class such that the visual semantics of our input image does not get hampered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversaries(image_tensor, delta, model, true_class_index):\n",
    "    # Loss and optimizer\n",
    "    scc_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "    for t in range(50):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(delta)\n",
    "            inp = preprocess_input(image_tensor + delta)\n",
    "            predictions = model(inp, training=False)\n",
    "            loss = - scc_loss(\n",
    "                    tf.convert_to_tensor([true_class_index]),\n",
    "                    predictions\n",
    "                )\n",
    "            if t % 5 == 0:\n",
    "                print(t, loss.numpy())\n",
    "            \n",
    "        # Get the gradients\n",
    "        gradients = tape.gradient(loss, delta)\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.apply_gradients([(gradients, delta)])\n",
    "\n",
    "        # Project the delta back (l-infinite norm)\n",
    "        delta.assign_add(clip_eps(delta))\n",
    "\n",
    "    return delta\n",
    "\n",
    "def perturb_image(image_path, true_class_index, model):\n",
    "    # Load and preprocess image but a but without any `preprocess_input`\n",
    "    sample_image = show_image(image_path)\n",
    "    preprocessed_image = preprocess_image_without(sample_image)\n",
    "\n",
    "    # Generate predictions before any adversaries\n",
    "    unsafe_preds = model.predict(preprocess_input(preprocessed_image))\n",
    "    print(\"Prediction before adv.:\", decode_predictions(unsafe_preds, top=3)[0])\n",
    "\n",
    "    # Initialize the perturbation quantity\n",
    "    image_tensor = tf.constant(preprocessed_image, dtype=tf.float32)\n",
    "    delta = tf.Variable(tf.zeros_like(image_tensor), trainable=True)\n",
    "\n",
    "    # Get the learned delta\n",
    "    delta_tensor = generate_adversaries(image_tensor, delta, model, true_class_index)\n",
    "\n",
    "    # See if the image changes\n",
    "    plt.imshow((image_tensor + delta_tensor).numpy().squeeze()/255)\n",
    "    plt.show()\n",
    "\n",
    "    # Generate prediction\n",
    "    perturbed_image = preprocess_input(image_tensor + delta_tensor)\n",
    "    preds = model.predict(perturbed_image)\n",
    "    print(\"Prediction after adv.:\", decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that the hyperparameters like learning rate, number of epochs were determined after empirical experiments and also by referring to [this tremendous tutorial](https://adversarial-ml-tutorial.org/introduction/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching a simple attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_image(\"pig.jpg\", 341, resnet50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('miniconda3': conda)",
   "language": "python",
   "name": "python37164bitminiconda3condafb3a99d547424b5988e77943e2f3ad61"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
